# Laptop code
import threading
import socket
import pickle
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Subset
import torchvision.transforms as transforms
import struct
from tqdm import tqdm
import copy
import warnings
import random
import torch.nn as nn
import torchvision.models as torch_models

warnings.filterwarnings("ignore")

####################################################### 수정 가능 #######################################################
target_accuracy = 80.0  # 사용자 편의에 맞게 조정
global_round = 30   # 사용자 편의에 맞게 조정

batch_size = 64  # 사용자 편의에 맞게 조정
num_samples = 10000   # 사용자 편의에 맞게 조정
# host = ''  # laptop ip 기입 (실제 연합학습 시 아래 loopback ip는 주석 처리)
host = '127.0.0.1' # loopback으로 연합학습 수행 시 사용될 ip
port = 8080 # 1024번 ~ 65535번


transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
# # Network도 사용자 편의에 맞게 조정 (client와 server의 network와 동일)
# class Network(nn.Module):
#     def __init__(self):
#         super(Network, self).__init__()

#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5, stride=1, padding=2)
#         self.bn1 = nn.BatchNorm2d(12)
#         self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=2)
#         self.bn2 = nn.BatchNorm2d(12)
#         self.pool = nn.MaxPool2d(2,2)
#         self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=2)
#         self.bn4 = nn.BatchNorm2d(24)
#         self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=2)
#         self.bn5 = nn.BatchNorm2d(24)
#         self.fc1 = nn.Linear(24*16*16, 10)

#     def forward(self, input):
#         output = F.relu(self.bn1(self.conv1(input))) #32 x 32 x3 -> 32 x 32 x 12
#         output = F.relu(self.bn2(self.conv2(output)))
#         output = self.pool(output)
#         output = F.relu(self.bn4(self.conv4(output)))
#         output = F.relu(self.bn5(self.conv5(output)))
#         output = output.view(output.size(0),-1)
#         output = self.fc1(output)

#         return output


class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.downsample = downsample

    def forward(self, x):
        residual = x
        if self.downsample is not None:
            residual = self.downsample(x)
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += residual
        return F.relu(out)

# ResNet32 test 30분 74%
class ResNetCIFAR(nn.Module):
    def __init__(self, block, layers, num_classes=10):
        super(ResNetCIFAR, self).__init__()
        self.in_channels = 16
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(16)
        self.layer1 = self._make_layer(block, 16, layers[0])
        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)
        self.fc = nn.Linear(64, num_classes)
        self.dropout = nn.Dropout(0.5)

    def _make_layer(self, block, out_channels, blocks, stride=1):
        downsample = None
        if stride != 1 or self.in_channels != out_channels * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels * block.expansion),
            )
        layers = []
        layers.append(block(self.in_channels, out_channels, stride, downsample))
        self.in_channels = out_channels * block.expansion
        for _ in range(1, blocks):
            layers.append(block(self.in_channels, out_channels))
        return nn.Sequential(*layers)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = F.avg_pool2d(x, 8)
        x = x.view(x.size(0), -1)
        x = self.dropout(x)
        return self.fc(x)

def Network():
    return ResNetCIFAR(BasicBlock, [5, 5, 5])  # ResNet-32 구성


# #30분 75퍼 용량 레즈넷32에 비해 12배 (경량화 적용 전)
# class DepthwiseSeparableConv(nn.Module):
#     def __init__(self, in_channels, out_channels, stride=1):
#         super(DepthwiseSeparableConv, self).__init__()
#         self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False)
#         self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)
#         self.bn1 = nn.BatchNorm2d(in_channels)
#         self.bn2 = nn.BatchNorm2d(out_channels)

#     def forward(self, x):
#         x = F.relu6(self.bn1(self.depthwise(x)))
#         x = F.relu6(self.bn2(self.pointwise(x)))
#         return x

# class Network(nn.Module):
#     def __init__(self, num_classes=10):
#         super(Network, self).__init__()
#         self.features = nn.Sequential(
#             nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False),
#             nn.BatchNorm2d(32),
#             nn.ReLU6(inplace=True),
#             DepthwiseSeparableConv(32, 64),
#             DepthwiseSeparableConv(64, 128, stride=2),
#             DepthwiseSeparableConv(128, 128),
#             DepthwiseSeparableConv(128, 256, stride=2),
#             DepthwiseSeparableConv(256, 256),
#             DepthwiseSeparableConv(256, 512, stride=2),
#             *[DepthwiseSeparableConv(512, 512) for _ in range(5)],
#             DepthwiseSeparableConv(512, 1024, stride=2),
#             DepthwiseSeparableConv(1024, 1024)
#         )
#         self.avg_pool = nn.AdaptiveAvgPool2d(1)
#         self.fc = nn.Linear(1024, num_classes)

#     def forward(self, x):
#         x = self.features(x)
#         x = self.avg_pool(x)
#         x = torch.flatten(x, 1)
#         x = self.fc(x)
#         return x


def measure_accuracy(global_model, test_loader):  # pruning or quantization 적용시 필요한 경우 코드 추가 가능
    model = Network()
    model.load_state_dict(global_model)
    model.to(device)
    model.eval()

    accuracy = 0.0
    total = 0.0

    inference_start = time.time()
    with torch.no_grad():
        print("\n")
        for inputs, labels in tqdm(test_loader, desc="Test"):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)

            predicted = torch.max(outputs, 1)[1]
            total += labels.size(0)
            accuracy += (predicted == labels).sum().item()

        accuracy = (100 * accuracy / total)
    inference_end = time.time()

    print(f"Inference time for {num_samples} images : {(inference_end - inference_start):.2f} seconds")

    return accuracy, model
##############################################################################################################################






####################################################### 수정 금지 ##############################################################
cnt = []
models = []  # 수신받은 model 저장할 리스트
semaphore = threading.Semaphore(0)

global_model = None
global_accuracy = 0.0
current_round = 0
device = 'cuda' if torch.cuda.is_available() else 'cpu'

def handle_client(conn, addr, model, test_loader):
    global models, global_model, global_accuracy, current_round, cnt
    print(f"Connected by {addr}")

    while True:
        if len(cnt) < 2:
            cnt.append(1)
            weight = pickle.dumps(dict(model.state_dict().items()))
            conn.send(struct.pack('>I', len(weight)))
            conn.send(weight)

        data_size = struct.unpack('>I', conn.recv(4))[0]
        received_payload = b""
        remaining_payload_size = data_size
        while remaining_payload_size != 0:
            received_payload += conn.recv(remaining_payload_size)
            remaining_payload_size = data_size - len(received_payload)
        model = pickle.loads(received_payload)

        models.append(model)

        if len(models) == 2:
            current_round += 1
            global_model = average_models(models)
            global_accuracy, global_model = measure_accuracy(global_model, test_loader)
            print(f"Global round [{current_round} / {global_round}] Accuracy : {global_accuracy}%")
            get_model_size(global_model)
            models = []
            semaphore.release()
        else:
            semaphore.acquire()

        if (current_round == global_round) or (global_accuracy >= target_accuracy):
            weight = pickle.dumps(dict(global_model.state_dict().items()))
            conn.send(struct.pack('>I', len(weight)))
            conn.send(weight)
            conn.close()
            break
        else:
            weight = pickle.dumps(dict(global_model.state_dict().items()))
            conn.send(struct.pack('>I', len(weight)))
            conn.send(weight)

def get_model_size(global_model):
    model_size = len(pickle.dumps(dict(global_model.state_dict().items())))
    print(f"Model size : {model_size / (1024 ** 2):.4f} MB")

def get_random_subset(dataset, num_samples):
    if num_samples > len(dataset):
        raise ValueError(f"num_samples should not exceed {len(dataset)} (total number of samples in test dataset).")

    indices = random.sample(range(len(dataset)), num_samples)
    subset = Subset(dataset, indices)
    return subset

def average_models(models):
    weight_avg = copy.deepcopy(models[0])

    for key in weight_avg.keys():
        for i in range(1, len(models)):
            weight_avg[key] += models[i][key]
        weight_avg[key] = torch.div(weight_avg[key], len(models))

    return weight_avg


def main():
    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server.bind((host, port))
    server.listen()
    connection = []
    address = []

    test_dataset = torch.load('./data/test_image/test_dataset.pt')

    test_dataset = get_random_subset(test_dataset, num_samples)

    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    print(f"Server is listening on {host}:{port}")
    model = Network()

    while len(address) < 2 and len(connection) < 2:
        conn, addr = server.accept()
        connection.append(conn)
        address.append(addr)

    training_start = time.time()

    connection1 = threading.Thread(target=handle_client, args=(connection[0], address[0], model, test_loader))
    connection2 = threading.Thread(target=handle_client, args=(connection[1], address[1], model, test_loader))

    connection1.start();connection2.start()
    connection1.join();connection2.join()

    training_end = time.time()
    total_time = training_end - training_start
    print(f"\nTraining time: {int(total_time // 3600)} hours {int((total_time % 3600) // 60)} minutes {(total_time % 60):.2f} seconds")

    print("Federated Learning finished")


if __name__ == "__main__":
    main()
##############################################################################################################################

